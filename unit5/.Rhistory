save(perth,file="perthtwit.R")
save(perth,file="perthtwit.Rdata")
melb<-searchTwitter('abbott', geocode='-37.807071,144.939773,50km', n=1500)
melb_df<-twListToDF(melb)
View(melb_df)
length(melb_df[melb_df$favoriteCount>20])
length(melb_df[melb_df$favoriteCount>20,])
length(melb_df[melb_df$favoriteCount>10,])
length(melb_df[melb_df$favoriteCount>5,])
dims(melb_df[melb_df$favoriteCount>5,])
dim(melb_df[melb_df$favoriteCount>5,])
dim(melb_df[melb_df$favoriteCount>2,])
dim(melb_df[melb_df$retweetCount>2,])
dim(melb_df[melb_df$retweetCount>30,])
dim(melb_df[melb_df$retweetCount>50,])
dim(melb_df[melb_df$retweetCount>80,])
kip<-melb_df[melb_df$retweetCount>80,]
table(kip[c(11,3)])
table(kip[c(11,12)])
abbot_brittney<-melb_df[melb_df$screenName=="abbott_brittney",]
View(abbot_brittney)
abbot_brittney<-melb_df[melb_df$screenName=="ALLANPHC",]
View(abbot_brittney)
setwd("~/Documents/r_code/Presidential-Semantic-Analysis")
setwd("~/Documents/r_code/Presidential-Semantic-Analysis")
hip<-president()
source('~/Documents/r_code/Presidential-Semantic-Analysis/presidentialsemantics.R', echo=TRUE)
install.packages("ggplot2")
source('~/Documents/r_code/Presidential-Semantic-Analysis/presidentialsemantics.R', echo=TRUE)
source('~/Documents/r_code/Presidential-Semantic-Analysis/presidentialsemantics.R', echo=TRUE)
ans<-president()
source('~/Documents/r_code/Presidential-Semantic-Analysis/ScoreSentiment.R', echo=TRUE)
ans<-president()
positive.words <- scan("~/opinion-lexicon-English/positive-words.txt", what='character',comment.char=';')
positive.words <- scan("opinion-lexicon-English/positive-words.txt", what='character',comment.char=';')
negative.words <- scan("opinion-lexicon-English/negative-words.txt", what='character',comment.char=';')
ans<-president()
ans
View(ans)
textPerth=laply(perth, function(t) t$getText())
resultPerth=score.sentiment(textPerth, positive.words, negative.words)
View(resultPerth)
sum(resultPerth>0)
sum(resultPerth$score>0)
sum(resultPerth$score<0)
sum(resultPerth$score==0)
setwd("~/Documents/r_code")
install.packages(pkgs="sentiment_0.2.tar.gz", type="source", repos=NULL)
install.packages("Rstem")
install.packages("Rstem", repos = "http://www.omegahat.org/R")
library(qdap)
install.packages("qdap")
save(melb,file="melbtwit.Rdata")
sum(resultPerth$score<0)
sum(resultPerth$score<0)
sum(resultPerth$score==0)
sum(resultPerth$score>0)
textMelb=laply(melb, function(t) t$getText())
resultMelb=score.sentiment(textMelb, positive.words, negative.words)
sum(resultMelb$score>0)
sum(resultMelb$score<0)
sum(resultMelb$score==0)
dt<-load("melbtwit.R")
?load
load("melbtwit.Rdata",.GlobalEnv)
df<-twListToDF(melb)
library(twitteR)
df<-twListToDF(melb)
df[1,1]
library(qdap)
x<-df[1,1]
x
polarity(x)
View(df)
x<-polarity(df$text)
gsub("[^[:alnum:]///' ]", "", df)
df2<-gsub("[^[:alnum:]///' ]", "", df)
df2<-gsub("[^[:alnum:]///' ]", "", df$text)
df2
df2[1]
x<-polarity(df2)
x
vapply
?vapply
x<-vapply(df2,polarity)
x<-lapply(df2,polarity)
head(x)
?polarity
polarity(df2,grouping.var=1:1500)
x<-polarity(df2,grouping.var=1:1500)
head(x)
x[1,1]
x[1]
df2[1:10]
hip<-df2[1:10]
hip
polarity(hip)
polarity(hip,grouping=1:10)
x<-polarity(df2,grouping=1:1500)
heaed(x)
head(X)
head(x)
hip<-df2[1:500]
x<-polarity(hip,grouping=1:500)
x
x$500
x[1,1]
x[1,2]
x[1,3]
hip<-df2[1:10]
hip
polarity(hip,grouping=1:10)
x<-polarity(hip,grouping=1:10)
dim(x)
x<-polarity(hip,grouping.var=1:10)
x
dim(x)
y<-1:10
cbind(y,hip)
hik<-cbind(y,hip)
y<-as.numeric(1:10)
hik<-cbind(y,hip)
hik[1,1]
hik[1,2]
x<-polarity(hip,grouping.var=y)
x
dim(x)
x$y
polarity(hip,grouping.var=y)
polarity(hip,grouping.var=all)
polarity(hip,all)
polarity(hip)$all
polarity(hip)$group
polarity(hip)$digits
polarity(hip)$all
df<-polarity(hip)$all
df
df$polarity
hip<-polarity(df2)$all
sum(hip$polarity>0)
sum(hip$polarity<0)
sum(hip$polarity==0)
load('perthtwit.Rdata')
pdf<-twListToDF(perth)
perth_sent<-polarity(pdf$text)$all
perth_sent<-polarity(gsub("[^[:alnum:]///' ]", "",pdf$text)$all
)
perth_sent<-polarity(gsub("[^[:alnum:]///' ]", "",pdf$text))$all
sum(perth_sent$polarity==0)
sum(perth_sent$polarity<0)
sum(perth_sent$polarity>0)
head(perth_sent)
perth_sent$neg.words
perth_text<-gsub("[^[:alnum:]///' ]", "",pdf$text)
perth_text<-gsub("-", "",pdf$text)
perth_sent<-polarity(perth_sent)$all
head(perth_sent)
perth_sent$pos.words
perth_sent$neg.words
sum(perth_sent$polarity<0)
sum(perth_sent$polarity>0)
pol<-perth_sent$polarity
head(pol)
head(pdf)
head(pdf$text)
perth_text<-pdf$text
pertht2<-gsub("[^[:alnum:]///' ]", "",perth_text)
head(pertht2)
grep(pertht2,"-")
?grep
grep("-",pertht2)
grepl("-",pertht2)
kip<-polarity(pertht2)$all
head(kip)
pos<-kip$pos.words
pos
grep("-",pos)
grepl("-",pos)
pos[grepl("-",pos)]
pos[!grepl("-",pos)]
View(hip)
View(hip)
sum(hip$polarity<0)
sum(hip$polarity>0)
sum(hip$polarity==0)
head(kip)
negwords<-kip$neg.words
negwords<-negwords[!grepl("-",negwords)]
negwords
library(wordcloud)
wordcloud(negwords)
?wordcloud
wordcloud(perth_text)
negwords
wordcorp<-Corpus(negwords)
Corpus(negwords)
?Corpus
Corpus(perth_text)
negwords<-sapply(negwords, function(x) x$getText())
negwords<-sapply(negwords, function(x) getText())
library(tm)
?getText
unlist(negwords)
Corpus(unlist(negwords))
Corpus(VectorSource(unlist(negwords)))
corp<-Corpus(VectorSource(unlist(negwords)))
wordcloud(corp)
neg
neg<-hip$polarity<0
pos<-hip$polarity>0
sum(neg)
mean(neg)
mean(pos)
dim(neg)
neg
pos<-hip[hip$polarity>0]
pos<-hip[hip$polarity>0,]
pos<-subset(hip, polarity>0)
neg<-subset(hip, polarity<0)
head(pos)
sum(pos$polarity)
sum(neg$polarity)
hip[hip$polarity<0]
hip[hip$polarity<0,]
hip$polarity[hip$polarity<0,]
hip$polarity[hip$polarity<0]
load("melbtwit.Rdata")
source('~/Documents/r_code/poly_analysis.R', echo=TRUE)
wordcloud(melb_corp)
m2<-searchTwitter('abbott', geocode='-37.807071,144.939773,50km', n=10)
load("twitter auth.Rdata")
registerTwitterOAuth(cred)
registerTwitterOAuth(twitCred)
m2<-searchTwitter('abbott', geocode='-37.807071,144.939773,50km', n=10)
m2
m2<-searchTwitter('#abbott', geocode='-37.807071,144.939773,50km', n=10)
twListToDF(m2)
m2<-searchTwitter('#Auspol', geocode='-37.807071,144.939773,50km', n=10)
twListToDF(m2)
m2<-searchTwitter('pyne', geocode='-37.807071,144.939773,50km', n=10)
twListToDF(m2)
library(ggplot2)
str(mpg)
$drv
qplot(displ,hwy,data=mpg)
qplot(displ,year,data=mpg)
qplot(model,cty,data=mpg)
qplot(displ,cty,data=mpg)
qplot(displ,cty,data=mpg, color=drv)
qplot(displ,cty,data=mpg, color=manufacturer)
qplot(displ,cty,data=mpg, color=class)
qplot(displ,cty,data=mpg, color=class, geom=c("point","smooth")
)
qplot(displ,cty,data=mpg, color=class, geom=c("point","smooth"),facets=.~class)
qplot(displ,cty,data=mpg, color=class, geom=c("point","smooth"),facets=.~drv)
qplot(displ,cty,data=mpg, geom=c("point","smooth"),facets=.~drv)
str(mpg)
qplot(displ,data=mpg)
qplot(cty,color=cyl,data=mpg)
qplot(cty,color=drv,data=mpg)
qplot(cty,fill=drv,data=mpg)
qplot(cty,fill=drv,data=mpg,geom="density")
qplot(cty,data=mpg,geom="density")
qplot(cty,data=mpg,geom="density",color=drv)
qplot(cty,data=mpg,geom="density",color=fl)
qplot(cty,data=mpg,geom="density",color=class)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
head(Diet)
str(Bodyweight)
str(nlme)
str(weight)
xyplot(weight ~ Time | Diet, BodyWeight)
library(datasets)
data(airquality)
qplot(Wind,Ozone, data=airquality, facets = .~factor(Month))
library(ggplor2)
library(ggplot2)
qplot(Wind,Ozone, data=airquality, facets = .~factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies, panel = panel.loess)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + stats_smooth("loess")
g <- ggplot(movies, aes(votes, rating), data =movies)
ggplot(movies, aes(votes, rating)) + geom_point()
average_weekly_income <- read.csv("~/Desktop/aus stats/average_weekly_income/average_weekly_income.csv")
View(average_weekly_income)
plot(average_weekly_income$awi)
plot(average_weekly_income$awi,"l")
plot(average_weekly_income$awi,average_weekly_income$date"l")
plot(average_weekly_income$awi,average_weekly_income$date,"l")
a=average_weekly_income
a$date = as.POSIXlt(a$date,"%d/%m/%Y")
a$date = as.POSIXlt(a$date,"%d/%m/%y")
a$date = as.Date(strptime(a$date,"%d/%m/%y"))
plot(a$date,a$awi)
average_weekly_income <- read.csv("~/Desktop/aus stats/average_weekly_income/average_weekly_income.csv")
View(average_weekly_income)
a=average_weekly_income
a$date = as.Date(strptime(a$date,"%d/%m/%y"))
plot(a$date,a$awi)
a$date
str(a)
str(average_weekly_income)
a = average_weekly_income
a[1]
a[1,1]
as.Date(strptime(a[1,1],"%d/%m/%y"))
as.POSIXlt(a[1,1],"%d/%m/%y")
as.POSIXlt(a[1,1],"%d/%m/%Y")
?strptime
as.Date(strptime(a[1,1],"%d/%m/%Y"))
a$date = as.Date(strptime(a$date,"%d/%m/%Y"))
plot(a$date,a$awi)
plot(a$date,a$awi,"l")
cor(a$awi,a$date)
lm(date~awi,data=a)
model = lm(date~awi,data=a)
summary(model)
model$residuals
model = lm(awi ~ date,data=a)
summary(model)
average_weekly_income <- read.csv("~/Desktop/aus stats/average_weekly_income/average_weekly_income.csv")
View(average_weekly_income)
a= average_weekly_income
a[1,1]
as.POSIXlt(a[1,1],"%d/%m/%Y")
strptime(a[1,1],"%d/%m/%Y")
as.Date(strptime(a[1,1],"%d/%m/%Y"))
a$date=as.Date(strptime(a$date,"%d/%m/%Y"))
plot(a$date,a$awi,"l")
model = lm(awi ~ date, data = a)
summary(model)
predict(model,data.frame(date="2016-01-01"))
predict(model,data.frame(date=as.Date("2016-01-01"))
)
predict(model,data.frame(date=as.Date("2014-01-01")))
predict(model)
b=subset(a,date > as.Date("1980-01-01"))
model2 = lm(awi ~ date, data =b)
summary(model2)
predict(model2)
p=predict(model2)
model2residuals
model2$residuals
model$residuals
plot(log(a$awi),a$date)
plot(a$date,log(a$awi))
model3 = lm(log(awi)~date,data=b)
summary(model3)
summary(model2)
p=exp(predict(model3))
p
p-b$awi
plot(a$date,log(a$awi),"l")
plot(a$date,a$awi,"l")
plot(a$date,exp(a$awi),"l")
plot(a$date,a$awi,"l")
plot(a$date,log(a$awi),"l")
hpi <- read.csv("~/Desktop/aus stats/housing/house_price_index.csv", header=FALSE)
View(hpi)
plot(hpi$v2)
plot(hpi$V2)
plot(hpi$V1,hpi$V2)
hpi$V1 = as.Date(strptime(hpi$V1,"%d/%m/%Y"))
plot(hpi$V1,hpi$V2)
plot(hpi$V1,hpi$V2,"l")
plot(hpi$V1,hpi$V2,"l")
line(a$date,a$awi)
lines(a$date,a$awi)
plot(a$date,log(a$awi),"l")
lines(hpi$V1,hpi$V2)
lines(hpi$V1,hpi$V2,colour="red")
lines(hpi$V1,hpi$V2,color="red")
lines(hpi$V1,hpi$V2)
plot(a$date,a$awi,"l")
lines(hpi$V1,hpi$V2)
interest_rate <- read.csv("~/Desktop/aus stats/housing/interest_rate.csv", stringsAsFactors=FALSE)
View(interest_rate)
ir = interest_rate
ir$date=as.Date(strptime(ir$date,"%d/%m/%Y"))
plot($ir$date,ir$rate)
plot(ir$date,ir$rate)
plot(ir$date,ir$rate,"l")
interest_rate <- read.csv("~/Desktop/aus stats/housing/interest_rate.csv", stringsAsFactors=FALSE)
View(interest_rate)
ir$date=as.Date(strptime(ir$date,"%d/%m/%Y"))
ir = interest_rate
ir$date=as.Date(strptime(ir$date,"%d/%m/%Y"))
plot(ir$date,ir$rate,"l")
which.max(ir$rate)
ir[[1758]]
ir[1758,]
setwd("~/Documents/r_code/edx/unit5")
emails <- read.csv("~/Documents/r_code/edx/unit5/emails.csv", stringsAsFactors=FALSE)
View(emails)
table(emails$spam)
max(nchar(emails$text))
which.min(nchar(emails$text))
library(tm)
library(SnowballC)
library(caTools)
library(ROCR)
library(rpart)
library(rpart.plot)
corpus = Corpus(VectorSource(emails$text))
corpus = = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, c(stopwords("english")))
corpus = tm_map(corpus, stemDocument)
dtm = DocumentTermMatrix(corpus)
dtm
spdtm = removeSparseTerms(dtm, 0.95)
spdtm
emailsSparse = as.data.frame(as.matrix(spdtm))
colnames(emailsSparse) = make.names(colnames(emailsSparse))
colSums(emailsSparse)
sort(colSums(emailsSparse))
emailsSparse$spam = emails$spam
View(emailsSparse)
head(emails$spam)
head(emailsSparse$spam)
sort(colSums(emailsSparse$spam==1))
qq = subset(emailsSparse, spam ==1)
sort(colSums(qq))
table(emailsSparse$spam)
table(emails$spam)
qq = subset(emailsSparse, spam ==0)
sort(colSums(qq))
qq = subset(emailsSparse, spam ==1)
sort(colSums(qq))
set.seed(123)
emailsSparse$spam = as.factor(emailsSparse$spam)
set.seed(123)
spl = sample.split(emailsSparse$spam, SplitRatio = 0.7)
train = subset(emailsSparse, spl == TRUE)
test = subset(emailsSparse, spl == FALSE)
library(randomForest)
spamLog = glm(spam ~., data = train, family=binomial)
spamCART = rpart(spam~., data = train, method="class")
set.seed(123)
spamRF = randomForest(spam ~ ., data=train)
predLog = predict(spamLog)
head(predLog)
predLog = predict(spamLog, train)
head(predLog)
predCART = predict(spamCART, train)
head(predCART)
predLog[,2]
predLog[,1]
predLog < 0.00001
sum(predLog < 0.00001)
sum(predLog > 0.99999)
sum(predLog > 0.00001 & predlog < 0.99999)
sum(predLog > 0.00001 & predLog < 0.99999)
4010 - 3056 - 954
summary(spamLog)
prp(spamCART)
table(train$spam, predLog > 0.5)
(3052+954)/nrow(train)
library(ROCR)
ROCRpred = prediction(predLog, train$spam)
auc = as.numeric(performance(ROCRpred,"auc")@y.values)
table(train$spam, predCART))
table(train$spam, predCART)
table(train$spam, predCART[,2])
table(train$spam, predCART[,2] > 0.5)
(2885+894)/nrow(train)
ROCRpred = prediction(predCART[,2], train$spam)
auc = as.numeric(performance(ROCRpred,"auc")@y.values)
predRF = predict(spamRF, train)
table(train$spam, predRF[,2] > 0.5)
head(predRF)
head(predRF[,2])
table(train$spam, predRF > 0.5)
table(train$spam, predRF)
(3046+958)/nrow(train)
ROCRpred = prediction(predRF, train$spam)
ROCRpred = prediction(predRF, train$spam, type="prob")
predRF = predict(spamRF, train, type = "prob")
ROCRpred = prediction(predRF, train$spam)
ROCRpred = prediction(predRF[,2], train$spam)
auc = as.numeric(performance(ROCRpred,"auc")@y.values)
predLog = predict(spamLog, test)
table(test$spam, predLog > 0.5)
(1258+376)/nrow(test)
ROCRpred = prediction(predLog, test$spam)
auc = as.numeric(performance(ROCRpred,"auc")@y.values)
predCART = predict(spamCART, test)
table(test$spam, predCART[,2] > 0.5)
(1228+386)/nrow(test)
ROCRpred = prediction(predCART[,2], test$spam)
auc = as.numeric(performance(ROCRpred,"auc")@y.values)
predRF = predict(spamRF, test)
table(test$spam, predRF)
(1290+386)/nrow(test)
ROCRpred = prediction(predRF[,2], test$spam)
ROCRpred = prediction(predRF, test$spam)
predRF = predict(spamRF, test, type = "prob")
ROCRpred = prediction(predRF[,2], test$spam)
auc = as.numeric(performance(ROCRpred,"auc")@y.values)
