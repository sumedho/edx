table(perth_df[c(11,3)])
perth_df[perth_df$retweetCount>12,]
perth_df[,perth_df$retweetCount>12]
gt<-subset(perth_df,perth_df$retweetCount>24)
gt
table(gt[c(11,3)])
gt<-subset(perth_df,perth_df$favoriteCount>24)
gt<-subset(perth_df,perth_df$favoriteCount>12)
gt<-subset(perth_df,perth_df$favoriteCount>5)
table(gt[c(11,3)])
gt[gt$screenName=="linessue",]
?load
save(perth,file="perthtwit.R")
save(perth,file="perthtwit.Rdata")
melb<-searchTwitter('abbott', geocode='-37.807071,144.939773,50km', n=1500)
melb_df<-twListToDF(melb)
View(melb_df)
length(melb_df[melb_df$favoriteCount>20])
length(melb_df[melb_df$favoriteCount>20,])
length(melb_df[melb_df$favoriteCount>10,])
length(melb_df[melb_df$favoriteCount>5,])
dims(melb_df[melb_df$favoriteCount>5,])
dim(melb_df[melb_df$favoriteCount>5,])
dim(melb_df[melb_df$favoriteCount>2,])
dim(melb_df[melb_df$retweetCount>2,])
dim(melb_df[melb_df$retweetCount>30,])
dim(melb_df[melb_df$retweetCount>50,])
dim(melb_df[melb_df$retweetCount>80,])
kip<-melb_df[melb_df$retweetCount>80,]
table(kip[c(11,3)])
table(kip[c(11,12)])
abbot_brittney<-melb_df[melb_df$screenName=="abbott_brittney",]
View(abbot_brittney)
abbot_brittney<-melb_df[melb_df$screenName=="ALLANPHC",]
View(abbot_brittney)
setwd("~/Documents/r_code/Presidential-Semantic-Analysis")
setwd("~/Documents/r_code/Presidential-Semantic-Analysis")
hip<-president()
source('~/Documents/r_code/Presidential-Semantic-Analysis/presidentialsemantics.R', echo=TRUE)
install.packages("ggplot2")
source('~/Documents/r_code/Presidential-Semantic-Analysis/presidentialsemantics.R', echo=TRUE)
source('~/Documents/r_code/Presidential-Semantic-Analysis/presidentialsemantics.R', echo=TRUE)
ans<-president()
source('~/Documents/r_code/Presidential-Semantic-Analysis/ScoreSentiment.R', echo=TRUE)
ans<-president()
positive.words <- scan("~/opinion-lexicon-English/positive-words.txt", what='character',comment.char=';')
positive.words <- scan("opinion-lexicon-English/positive-words.txt", what='character',comment.char=';')
negative.words <- scan("opinion-lexicon-English/negative-words.txt", what='character',comment.char=';')
ans<-president()
ans
View(ans)
textPerth=laply(perth, function(t) t$getText())
resultPerth=score.sentiment(textPerth, positive.words, negative.words)
View(resultPerth)
sum(resultPerth>0)
sum(resultPerth$score>0)
sum(resultPerth$score<0)
sum(resultPerth$score==0)
setwd("~/Documents/r_code")
install.packages(pkgs="sentiment_0.2.tar.gz", type="source", repos=NULL)
install.packages("Rstem")
install.packages("Rstem", repos = "http://www.omegahat.org/R")
library(qdap)
install.packages("qdap")
save(melb,file="melbtwit.Rdata")
sum(resultPerth$score<0)
sum(resultPerth$score<0)
sum(resultPerth$score==0)
sum(resultPerth$score>0)
textMelb=laply(melb, function(t) t$getText())
resultMelb=score.sentiment(textMelb, positive.words, negative.words)
sum(resultMelb$score>0)
sum(resultMelb$score<0)
sum(resultMelb$score==0)
dt<-load("melbtwit.R")
?load
load("melbtwit.Rdata",.GlobalEnv)
df<-twListToDF(melb)
library(twitteR)
df<-twListToDF(melb)
df[1,1]
library(qdap)
x<-df[1,1]
x
polarity(x)
View(df)
x<-polarity(df$text)
gsub("[^[:alnum:]///' ]", "", df)
df2<-gsub("[^[:alnum:]///' ]", "", df)
df2<-gsub("[^[:alnum:]///' ]", "", df$text)
df2
df2[1]
x<-polarity(df2)
x
vapply
?vapply
x<-vapply(df2,polarity)
x<-lapply(df2,polarity)
head(x)
?polarity
polarity(df2,grouping.var=1:1500)
x<-polarity(df2,grouping.var=1:1500)
head(x)
x[1,1]
x[1]
df2[1:10]
hip<-df2[1:10]
hip
polarity(hip)
polarity(hip,grouping=1:10)
x<-polarity(df2,grouping=1:1500)
heaed(x)
head(X)
head(x)
hip<-df2[1:500]
x<-polarity(hip,grouping=1:500)
x
x$500
x[1,1]
x[1,2]
x[1,3]
hip<-df2[1:10]
hip
polarity(hip,grouping=1:10)
x<-polarity(hip,grouping=1:10)
dim(x)
x<-polarity(hip,grouping.var=1:10)
x
dim(x)
y<-1:10
cbind(y,hip)
hik<-cbind(y,hip)
y<-as.numeric(1:10)
hik<-cbind(y,hip)
hik[1,1]
hik[1,2]
x<-polarity(hip,grouping.var=y)
x
dim(x)
x$y
polarity(hip,grouping.var=y)
polarity(hip,grouping.var=all)
polarity(hip,all)
polarity(hip)$all
polarity(hip)$group
polarity(hip)$digits
polarity(hip)$all
df<-polarity(hip)$all
df
df$polarity
hip<-polarity(df2)$all
sum(hip$polarity>0)
sum(hip$polarity<0)
sum(hip$polarity==0)
load('perthtwit.Rdata')
pdf<-twListToDF(perth)
perth_sent<-polarity(pdf$text)$all
perth_sent<-polarity(gsub("[^[:alnum:]///' ]", "",pdf$text)$all
)
perth_sent<-polarity(gsub("[^[:alnum:]///' ]", "",pdf$text))$all
sum(perth_sent$polarity==0)
sum(perth_sent$polarity<0)
sum(perth_sent$polarity>0)
head(perth_sent)
perth_sent$neg.words
perth_text<-gsub("[^[:alnum:]///' ]", "",pdf$text)
perth_text<-gsub("-", "",pdf$text)
perth_sent<-polarity(perth_sent)$all
head(perth_sent)
perth_sent$pos.words
perth_sent$neg.words
sum(perth_sent$polarity<0)
sum(perth_sent$polarity>0)
pol<-perth_sent$polarity
head(pol)
head(pdf)
head(pdf$text)
perth_text<-pdf$text
pertht2<-gsub("[^[:alnum:]///' ]", "",perth_text)
head(pertht2)
grep(pertht2,"-")
?grep
grep("-",pertht2)
grepl("-",pertht2)
kip<-polarity(pertht2)$all
head(kip)
pos<-kip$pos.words
pos
grep("-",pos)
grepl("-",pos)
pos[grepl("-",pos)]
pos[!grepl("-",pos)]
View(hip)
View(hip)
sum(hip$polarity<0)
sum(hip$polarity>0)
sum(hip$polarity==0)
head(kip)
negwords<-kip$neg.words
negwords<-negwords[!grepl("-",negwords)]
negwords
library(wordcloud)
wordcloud(negwords)
?wordcloud
wordcloud(perth_text)
negwords
wordcorp<-Corpus(negwords)
Corpus(negwords)
?Corpus
Corpus(perth_text)
negwords<-sapply(negwords, function(x) x$getText())
negwords<-sapply(negwords, function(x) getText())
library(tm)
?getText
unlist(negwords)
Corpus(unlist(negwords))
Corpus(VectorSource(unlist(negwords)))
corp<-Corpus(VectorSource(unlist(negwords)))
wordcloud(corp)
neg
neg<-hip$polarity<0
pos<-hip$polarity>0
sum(neg)
mean(neg)
mean(pos)
dim(neg)
neg
pos<-hip[hip$polarity>0]
pos<-hip[hip$polarity>0,]
pos<-subset(hip, polarity>0)
neg<-subset(hip, polarity<0)
head(pos)
sum(pos$polarity)
sum(neg$polarity)
hip[hip$polarity<0]
hip[hip$polarity<0,]
hip$polarity[hip$polarity<0,]
hip$polarity[hip$polarity<0]
load("melbtwit.Rdata")
source('~/Documents/r_code/poly_analysis.R', echo=TRUE)
wordcloud(melb_corp)
m2<-searchTwitter('abbott', geocode='-37.807071,144.939773,50km', n=10)
load("twitter auth.Rdata")
registerTwitterOAuth(cred)
registerTwitterOAuth(twitCred)
m2<-searchTwitter('abbott', geocode='-37.807071,144.939773,50km', n=10)
m2
m2<-searchTwitter('#abbott', geocode='-37.807071,144.939773,50km', n=10)
twListToDF(m2)
m2<-searchTwitter('#Auspol', geocode='-37.807071,144.939773,50km', n=10)
twListToDF(m2)
m2<-searchTwitter('pyne', geocode='-37.807071,144.939773,50km', n=10)
twListToDF(m2)
library(ggplot2)
str(mpg)
$drv
qplot(displ,hwy,data=mpg)
qplot(displ,year,data=mpg)
qplot(model,cty,data=mpg)
qplot(displ,cty,data=mpg)
qplot(displ,cty,data=mpg, color=drv)
qplot(displ,cty,data=mpg, color=manufacturer)
qplot(displ,cty,data=mpg, color=class)
qplot(displ,cty,data=mpg, color=class, geom=c("point","smooth")
)
qplot(displ,cty,data=mpg, color=class, geom=c("point","smooth"),facets=.~class)
qplot(displ,cty,data=mpg, color=class, geom=c("point","smooth"),facets=.~drv)
qplot(displ,cty,data=mpg, geom=c("point","smooth"),facets=.~drv)
str(mpg)
qplot(displ,data=mpg)
qplot(cty,color=cyl,data=mpg)
qplot(cty,color=drv,data=mpg)
qplot(cty,fill=drv,data=mpg)
qplot(cty,fill=drv,data=mpg,geom="density")
qplot(cty,data=mpg,geom="density")
qplot(cty,data=mpg,geom="density",color=drv)
qplot(cty,data=mpg,geom="density",color=fl)
qplot(cty,data=mpg,geom="density",color=class)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
head(Diet)
str(Bodyweight)
str(nlme)
str(weight)
xyplot(weight ~ Time | Diet, BodyWeight)
library(datasets)
data(airquality)
qplot(Wind,Ozone, data=airquality, facets = .~factor(Month))
library(ggplor2)
library(ggplot2)
qplot(Wind,Ozone, data=airquality, facets = .~factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies, panel = panel.loess)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + stats_smooth("loess")
g <- ggplot(movies, aes(votes, rating), data =movies)
ggplot(movies, aes(votes, rating)) + geom_point()
average_weekly_income <- read.csv("~/Desktop/aus stats/average_weekly_income/average_weekly_income.csv")
View(average_weekly_income)
plot(average_weekly_income$awi)
plot(average_weekly_income$awi,"l")
plot(average_weekly_income$awi,average_weekly_income$date"l")
plot(average_weekly_income$awi,average_weekly_income$date,"l")
a=average_weekly_income
a$date = as.POSIXlt(a$date,"%d/%m/%Y")
a$date = as.POSIXlt(a$date,"%d/%m/%y")
a$date = as.Date(strptime(a$date,"%d/%m/%y"))
plot(a$date,a$awi)
average_weekly_income <- read.csv("~/Desktop/aus stats/average_weekly_income/average_weekly_income.csv")
View(average_weekly_income)
a=average_weekly_income
a$date = as.Date(strptime(a$date,"%d/%m/%y"))
plot(a$date,a$awi)
a$date
str(a)
str(average_weekly_income)
a = average_weekly_income
a[1]
a[1,1]
as.Date(strptime(a[1,1],"%d/%m/%y"))
as.POSIXlt(a[1,1],"%d/%m/%y")
as.POSIXlt(a[1,1],"%d/%m/%Y")
?strptime
as.Date(strptime(a[1,1],"%d/%m/%Y"))
a$date = as.Date(strptime(a$date,"%d/%m/%Y"))
plot(a$date,a$awi)
plot(a$date,a$awi,"l")
cor(a$awi,a$date)
lm(date~awi,data=a)
model = lm(date~awi,data=a)
summary(model)
model$residuals
model = lm(awi ~ date,data=a)
summary(model)
average_weekly_income <- read.csv("~/Desktop/aus stats/average_weekly_income/average_weekly_income.csv")
View(average_weekly_income)
a= average_weekly_income
a[1,1]
as.POSIXlt(a[1,1],"%d/%m/%Y")
strptime(a[1,1],"%d/%m/%Y")
as.Date(strptime(a[1,1],"%d/%m/%Y"))
a$date=as.Date(strptime(a$date,"%d/%m/%Y"))
plot(a$date,a$awi,"l")
model = lm(awi ~ date, data = a)
summary(model)
predict(model,data.frame(date="2016-01-01"))
predict(model,data.frame(date=as.Date("2016-01-01"))
)
predict(model,data.frame(date=as.Date("2014-01-01")))
predict(model)
b=subset(a,date > as.Date("1980-01-01"))
model2 = lm(awi ~ date, data =b)
summary(model2)
predict(model2)
p=predict(model2)
model2residuals
model2$residuals
model$residuals
plot(log(a$awi),a$date)
plot(a$date,log(a$awi))
model3 = lm(log(awi)~date,data=b)
summary(model3)
summary(model2)
p=exp(predict(model3))
p
p-b$awi
plot(a$date,log(a$awi),"l")
plot(a$date,a$awi,"l")
plot(a$date,exp(a$awi),"l")
plot(a$date,a$awi,"l")
plot(a$date,log(a$awi),"l")
hpi <- read.csv("~/Desktop/aus stats/housing/house_price_index.csv", header=FALSE)
View(hpi)
plot(hpi$v2)
plot(hpi$V2)
plot(hpi$V1,hpi$V2)
hpi$V1 = as.Date(strptime(hpi$V1,"%d/%m/%Y"))
plot(hpi$V1,hpi$V2)
plot(hpi$V1,hpi$V2,"l")
plot(hpi$V1,hpi$V2,"l")
line(a$date,a$awi)
lines(a$date,a$awi)
plot(a$date,log(a$awi),"l")
lines(hpi$V1,hpi$V2)
lines(hpi$V1,hpi$V2,colour="red")
lines(hpi$V1,hpi$V2,color="red")
lines(hpi$V1,hpi$V2)
plot(a$date,a$awi,"l")
lines(hpi$V1,hpi$V2)
interest_rate <- read.csv("~/Desktop/aus stats/housing/interest_rate.csv", stringsAsFactors=FALSE)
View(interest_rate)
ir = interest_rate
ir$date=as.Date(strptime(ir$date,"%d/%m/%Y"))
plot($ir$date,ir$rate)
plot(ir$date,ir$rate)
plot(ir$date,ir$rate,"l")
interest_rate <- read.csv("~/Desktop/aus stats/housing/interest_rate.csv", stringsAsFactors=FALSE)
View(interest_rate)
ir$date=as.Date(strptime(ir$date,"%d/%m/%Y"))
ir = interest_rate
ir$date=as.Date(strptime(ir$date,"%d/%m/%Y"))
plot(ir$date,ir$rate,"l")
which.max(ir$rate)
ir[[1758]]
ir[1758,]
setwd("~/Documents/r_code/edx/unit4")
load("~/Documents/r_code/edx/unit4/assign2.RData")
letters$letter = as.factor(letters$letter)
set.seed(2000)
spl = sample.split(letters$letter, SplitRatio = 0.5)
library(caTools)
spl = sample.split(letters$letter, SplitRatio = 0.5)
train = subset(letters, spl == TRUE)
test = subset(letters, spl == FALSE)
table(test$letters)
summary(test$letters)
table(test$letter)
401/1558
library(rpart)
library(rpart.plot)
CARTb = rpart(letter ~ . -isB, data=train, method="class")
predCARTb = predict(CARTb, newdata = test, type = "class")
table(test$letter, predCARTb)
(348+318+363+340)/1558
libary(randomForest)
library(randomForest)
rforestB = randomForest(letter ~.-isB, data = train)
predFORB = predict(rforestB, newdata = test, type = "class")
table(test$letter, predFORB)
(390+380+393+369)/1558
census <- read.csv("~/Documents/r_code/edx/unit4/census.csv")
View(census)
set.seed(2000)
library(caTools)
set.seed(2000)
spl = sample.split(census$over50k, SplitRatio = 0.6)
train = subset(letters, spl == TRUE)
test = subset(letters, spl == FALSE)
train = subset(census, spl == TRUE)
test = subset(census, spl == FALSE)
19187/31978
model = glm(over50k ~., data = train, family=binomial)
summary(model)
census <- read.csv("~/Documents/r_code/edx/unit4/census.csv", stringsAsFactors=FALSE)
View(census)
set.seed(2000)
spl = sample.split(census$over50k, SplitRatio = 0.6)
train = subset(census, spl == TRUE)
test = subset(census, spl == FALSE)
model = glm(over50k ~., data = train, family=binomial)
census <- read.csv("~/Documents/r_code/edx/unit4/census.csv")
View(census)
set.seed(2000)
train = subset(census, spl == TRUE)
test = subset(census, spl == FALSE)
model = glm(over50k ~ ., data = train, family=binomial)
summary(model)
View(census)
predictTest = predict(model, type = "response", newdata = test)
table(test$over50k, predictTest > 0.5)
(9051+1888)/nrows(test)
(9051+1888)/nrow(test)
table(test$over50k)
9713/nrow(test)
library(ROCR)
ROCRpred = prediction(predictTest, test$over50k)
auc = as.numeric(performance(ROCRpred,"auc")@y.values)
CART = rpart(over50k ~., data=train, method="class")
prp(CART)
predCART = predict(CART, newdata = test, type = "class")
table(test$over50k, predCART)
(9243+1596)/nrow(test)
PredictROC = predict(CART, newdata = test)
pred = prediction(PredictROC[,2], test$over50k)
plot(perf)
perf = performance(pred, "tpr", "fpr")
plot(perf)
auc = as.numeric(performance(pred,"auc")@y.values)
set.seed(1)
trainSmall = train[sample(nrow(train), 2000), ]
libary(randomForest)
library(randomForest)
set.seed(1)
rforest = randomForest(over50k ~., data = trainSmall)
predFOR = predict(rforest, newdata = test, type = "class")
table(test$over50k, predFOR>0.5)
table(test$over50k, predFOR)
(9586+1093)/nrow(test)
vu = varUsed(rforest, count=TRUE)
vusorted = sort(vu, decreasing = FALSE, index.return = TRUE)
dotchart(vusorted$x, names(rforest$forest$xlevels[vusorted$ix]))
varImpPlot(rforest)
numFolds = trainControl( method = "cv", number = 10 )
library(caret)
library(e1071)
numFolds = trainControl( method = "cv", number = 10 )
cpGrid = expand.grid( .cp = seq(0.002,0.1,0.002))
train(over50k ~., data = train, method = "rpart", trControl = numFolds, tuneGrid = cpGrid )
CARTb = rpart(over50k ~., data=train, method="class", cp=0.002)
predCARTb = predict(CARTb, newdata = test, type = "class")
table(test$over50k, predCARTb)
(9178+1838)/nrow(test)
prp(CARTb)
